{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/a/Documents/DataScience_World/ML10_end_to_end/dsproject/CompleteDSproject/research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/a/Documents/DataScience_World/ML10_end_to_end/dsproject/CompleteDSproject'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/a/Documents/DataScience_World/ML10_end_to_end/dsproject/CompleteDSproject'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/Users/a/Documents/DataScience_World/ML10_end_to_end/dsproject/CompleteDSproject/\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adulteration_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>adulterant</th>\n",
       "      <th>detection_date</th>\n",
       "      <th>detection_method</th>\n",
       "      <th>severity</th>\n",
       "      <th>health_risk</th>\n",
       "      <th>action_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Butter</td>\n",
       "      <td>BrandB</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Artificial sweeteners</td>\n",
       "      <td>5/11/2024</td>\n",
       "      <td>Microbiological Analysis</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low</td>\n",
       "      <td>Product Recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chicken</td>\n",
       "      <td>BrandC</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>Coloring agents</td>\n",
       "      <td>5/23/2024</td>\n",
       "      <td>Sensory Evaluation</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Warning Issued</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Yogurt</td>\n",
       "      <td>BrandC</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Artificial sweeteners</td>\n",
       "      <td>2/17/2024</td>\n",
       "      <td>Sensory Evaluation</td>\n",
       "      <td>Severe</td>\n",
       "      <td>High</td>\n",
       "      <td>Investigation Launched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Wine</td>\n",
       "      <td>BrandB</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Coloring agents</td>\n",
       "      <td>5/16/2024</td>\n",
       "      <td>Spectroscopy</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Product Recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bread</td>\n",
       "      <td>BrandD</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>Water</td>\n",
       "      <td>6/6/2024</td>\n",
       "      <td>Chemical Analysis</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Warning Issued</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adulteration_id product_name   brand   category             adulterant  \\\n",
       "0                1       Butter  BrandB       Meat  Artificial sweeteners   \n",
       "1                2      Chicken  BrandC      Dairy        Coloring agents   \n",
       "2                3       Yogurt  BrandC       Meat  Artificial sweeteners   \n",
       "3                4         Wine  BrandB  Beverages        Coloring agents   \n",
       "4                5        Bread  BrandD      Dairy                  Water   \n",
       "\n",
       "  detection_date          detection_method  severity health_risk  \\\n",
       "0      5/11/2024  Microbiological Analysis  Moderate         Low   \n",
       "1      5/23/2024        Sensory Evaluation    Severe      Medium   \n",
       "2      2/17/2024        Sensory Evaluation    Severe        High   \n",
       "3      5/16/2024              Spectroscopy     Minor      Medium   \n",
       "4       6/6/2024         Chemical Analysis    Severe      Medium   \n",
       "\n",
       "             action_taken  \n",
       "0          Product Recall  \n",
       "1          Warning Issued  \n",
       "2  Investigation Launched  \n",
       "3          Product Recall  \n",
       "4          Warning Issued  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(\"artifacts/data_ingestion/data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   adulteration_id   1000 non-null   int64 \n",
      " 1   product_name      1000 non-null   object\n",
      " 2   brand             1000 non-null   object\n",
      " 3   category          1000 non-null   object\n",
      " 4   adulterant        1000 non-null   object\n",
      " 5   detection_date    1000 non-null   object\n",
      " 6   detection_method  1000 non-null   object\n",
      " 7   severity          1000 non-null   object\n",
      " 8   health_risk       1000 non-null   object\n",
      " 9   action_taken      1000 non-null   object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adulteration_id     0\n",
       "product_name        0\n",
       "brand               0\n",
       "category            0\n",
       "adulterant          0\n",
       "detection_date      0\n",
       "detection_method    0\n",
       "severity            0\n",
       "health_risk         0\n",
       "action_taken        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from src.datascience import logger\n",
    "from src.datascience.constants import *\n",
    "from src.datascience.utils.common import read_yaml, create_directories\n",
    "\n",
    "@dataclass\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    STATUS_FILE: Path\n",
    "    all_schema: dict\n",
    "    data_path: Path  # Added data_path to config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datascience.constants import *\n",
    "from src.datascience.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath=CONFIG_FILE_PATH, \n",
    "        params_filepath=PARAMS_FILE_PATH, \n",
    "        schema_filepath=SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        if not self.schema or \"COLUMNS\" not in self.schema:\n",
    "            raise ValueError(f\"Schema file at {schema_filepath} is missing or invalid. Ensure it contains a 'COLUMNS' key.\")\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        \"\"\"\n",
    "        Creates and returns the data validation configuration\n",
    "        \"\"\"\n",
    "        if \"COLUMNS\" not in self.schema:\n",
    "            raise KeyError(\"The schema file does not contain a 'COLUMNS' key.\")\n",
    "        \n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir=Path(self.config.data_validation.root_dir),\n",
    "            STATUS_FILE=Path(self.config.data_validation.STATUS_FILE),\n",
    "            all_schema=self.schema.COLUMNS,\n",
    "            data_path=Path(self.config.data_ingestion.local_data_file)  # Add data path from config\n",
    "        )\n",
    "        return data_validation_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.datascience import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidation:\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        self.config = config\n",
    "        self.validation_status = False\n",
    "        \n",
    "        # Ensure the validation directory exists\n",
    "        create_directories([self.config.root_dir])\n",
    "\n",
    "    def validate_all_columns(self) -> bool:\n",
    "        \"\"\"\n",
    "        Validates that all required columns exist in the dataset\n",
    "        Returns: bool indicating if validation passed\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = pd.read_csv(self.config.data_path)\n",
    "            schema_cols = list(self.config.all_schema.keys())\n",
    "            data_cols = list(data.columns)\n",
    "\n",
    "            # Check if all required columns exist\n",
    "            missing_cols = [col for col in schema_cols if col not in data_cols]\n",
    "            \n",
    "            if missing_cols:\n",
    "                self.validation_status = False\n",
    "                with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                    f.write(f\"Validation status: {self.validation_status}\\nMissing columns: {', '.join(missing_cols)}\")\n",
    "                return self.validation_status\n",
    "\n",
    "            self.validation_status = True\n",
    "            with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                f.write(f\"Validation status: {self.validation_status}\\nAll required columns present\")\n",
    "            return self.validation_status\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in validate_all_columns: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "    def validate_schema(self, data: pd.DataFrame) -> bool:\n",
    "        \"\"\"\n",
    "        Validates the data types of all columns against the schema\n",
    "        Args:\n",
    "            data: DataFrame to validate\n",
    "        Returns: bool indicating if validation passed\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.validation_status = True\n",
    "            validation_errors = []\n",
    "            \n",
    "            # Validate column data types\n",
    "            for column, expected_type in self.config.all_schema.items():\n",
    "                if expected_type == \"int\":\n",
    "                    valid = pd.api.types.is_integer_dtype(data[column])\n",
    "                elif expected_type == \"str\":\n",
    "                    valid = pd.api.types.is_string_dtype(data[column])\n",
    "                else:\n",
    "                    valid = False\n",
    "                    validation_errors.append(f\"Unsupported type {expected_type} for column {column}\")\n",
    "                \n",
    "                if not valid:\n",
    "                    self.validation_status = False\n",
    "                    validation_errors.append(f\"Invalid datatype for {column}: expected {expected_type}\")\n",
    "            \n",
    "            # Write validation results\n",
    "            with open(self.config.STATUS_FILE, 'a') as f:\n",
    "                f.write(\"\\n=== Schema Validation Results ===\\n\")\n",
    "                if validation_errors:\n",
    "                    f.write(\"\\n\".join(validation_errors))\n",
    "                f.write(f\"\\nSchema validation status: {self.validation_status}\")\n",
    "            \n",
    "            return self.validation_status\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in validate_schema: {str(e)}\")\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-08 09:28:38,684: INFO: 1615405803: Starting data validation]\n",
      "[2025-01-08 09:28:38,688: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-01-08 09:28:38,693: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-01-08 09:28:38,696: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-01-08 09:28:38,698: INFO: common: created directory at: artifacts]\n",
      "[2025-01-08 09:28:38,699: INFO: common: created directory at: artifacts/data_validation]\n",
      "[2025-01-08 09:28:38,700: INFO: 1615405803: Validating columns...]\n",
      "[2025-01-08 09:28:38,707: INFO: 1615405803: Validating schema...]\n",
      "[2025-01-08 09:28:38,713: INFO: 1615405803: Data validation completed successfully]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "        logger.info(\"Starting data validation\")\n",
    "        config_manager = ConfigurationManager()\n",
    "        data_validation_config = config_manager.get_data_validation_config()\n",
    "        data_validation = DataValidation(data_validation_config)\n",
    "        \n",
    "        # Validate columns\n",
    "        logger.info(\"Validating columns...\")\n",
    "        columns_valid = data_validation.validate_all_columns()\n",
    "        if not columns_valid:\n",
    "            raise ValueError(\"Column validation failed\")\n",
    "            \n",
    "        # Validate schema\n",
    "        logger.info(\"Validating schema...\")\n",
    "        data = pd.read_csv(data_validation_config.data_path)\n",
    "        schema_valid = data_validation.validate_schema(data)\n",
    "        if not schema_valid:\n",
    "            raise ValueError(\"Schema validation failed\")\n",
    "            \n",
    "        logger.info(\"Data validation completed successfully\")\n",
    "        \n",
    "except Exception as e:\n",
    "        logger.error(f\"Data validation failed: {str(e)}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "completeds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
